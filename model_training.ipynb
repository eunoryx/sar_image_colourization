{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model training is complicated, and takes very long! \n",
    "\n",
    "unfortunately, if we managed to test all these optimization functions, we'd run out of time, even with a dataset that's been downsized. \n",
    "we've chosen to leave them untrained for the time being.\n",
    "we will test out the following optimization functions in the future, outlined in the README\n",
    "\n",
    "during training, there will be dimensional shifts (using the view() and the permute() functions, among others).\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAR_set(Dataset):                                                         #dataset class\n",
    "\n",
    "    def __init__(self):                                                         #directory/path stuff\n",
    "\n",
    "        self.img_dir = r\"data/data_sub\"   \n",
    "        self.folder_path = sorted(os.listdir(self.img_dir))\n",
    "        self.colour_path = os.path.join(self.img_dir, self.folder_path[0])\n",
    "        self.gray_path = os.path.join(self.img_dir, self.folder_path[1])\n",
    "        self.len_data = len(os.listdir(self.gray_path))\n",
    "\n",
    "    def path_to_np(self, filepath, grayscale):                                  #ndarray convert\n",
    "        img = Image.open(filepath)\n",
    "\n",
    "        if grayscale:\n",
    "            img = img.convert(\"L\")\n",
    "\n",
    "        img = img.resize((128, 128))\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        return img_np\n",
    "\n",
    "    def rgb_to_lab(self, np_arr):                                               #rgb to lab tensor conversion\n",
    "\n",
    "        img_lab = cv.cvtColor(np_arr, cv.COLOR_RGB2LAB)\n",
    "        img_lab_tensor = torch.tensor(img_lab, dtype = torch.float32)\n",
    "\n",
    "        return img_lab_tensor\n",
    "\n",
    "    def __len__(self):                                                          #len fn\n",
    "\n",
    "        return self.len_data\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        colour_list = os.listdir(self.colour_path)\n",
    "        colour_file_path = os.path.join(self.colour_path, colour_list[idx])\n",
    "\n",
    "        img_np = self.path_to_np(colour_file_path, 0)\n",
    "        img_lab_tensor = self.rgb_to_lab(img_np)\n",
    "\n",
    "        gray_list = os.listdir(self.gray_path)\n",
    "        gray_file_path = os.path.join(self.gray_path, gray_list[idx])\n",
    "\n",
    "        gray_tensor = torch.tensor(self.path_to_np(gray_file_path, 1))\n",
    "        \n",
    "        gray_tensor = gray_tensor / 255.0\n",
    "        img_lab_tensor = img_lab_tensor / 255.0\n",
    "\n",
    "        return gray_tensor, img_lab_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SAR_set()                                                                                 #dataset\n",
    "\n",
    "train_size = int(0.8 * len(dataset))                                                                #test-train split\n",
    "test_size = len(dataset) - train_size  \n",
    "train_dataset,test_dataset = (dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 4, shuffle=False)                         #test-train dataloaders\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_Unit(nn.Module):                                                                     #condensing a convolutional unit\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, is_branch):\n",
    "\n",
    "        super(Conv_Unit, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_dim, out_dim, kernel_size = (3, 3))                            #convolution\n",
    "        self.bn = nn.BatchNorm2d(out_dim)                                                       #batch normalization\n",
    "        self.relu = nn.LeakyReLU()                                                              #leaky ReLU\n",
    "        self.is_branch = is_branch\n",
    "\n",
    "    def forward(self, flow):\n",
    "\n",
    "        flow = self.conv(flow)\n",
    "\n",
    "        if self.is_branch == 0:\n",
    "\n",
    "            flow = self.bn(flow)\n",
    "            flow = self.relu(flow)\n",
    "            \n",
    "        return flow\n",
    "    \n",
    "class Pooling_Unit(nn.Module):                                                                  #condensing a pooling unit\n",
    "\n",
    "    def __init__(self, in_dim):\n",
    "\n",
    "        super(Pooling_Unit, self).__init__()\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(in_dim)                                                        #batch normalization\n",
    "        self.relu = nn.LeakyReLU()                                                              #leaky ReLU\n",
    "        self.max_pool = nn.MaxPool2d(2, stride = (2, 2))                                        #max pooling\n",
    "\n",
    "    def forward(self, flow):\n",
    "        flow = self.bn(flow)\n",
    "        flow = self.relu(flow)\n",
    "        flow = self.max_pool(flow)\n",
    "\n",
    "class Trans_Conv_Unit(nn.Module):                                                               #condensing a transposed convolutional unit\n",
    "\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "\n",
    "        super(Trans_Conv_Unit, self).__init__()\n",
    "\n",
    "        self.conv_t = nn.ConvTranspose2d(in_dim, out_dim, kernel_size = (3, 3), padding = 1)    #transposed convolution\n",
    "        self.bn = nn.BatchNorm2d(out_dim)                                                       #batch normalization\n",
    "        self.relu = nn.LeakyReLU()                                                              #leaky ReLU\n",
    "\n",
    "    def forward(self, flow):\n",
    "        \n",
    "        flow = self.conv_t(flow)\n",
    "        flow = self.bn(flow)\n",
    "        flow = self.relu(flow)\n",
    "\n",
    "        return flow\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAR_UNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super(SAR_UNet, self).__init__()\n",
    "\n",
    "        self.encoder_1 = nn.Sequential(\n",
    "            \n",
    "            Conv_Unit(1, 64, 0),                     #1 conv\n",
    "            Conv_Unit(64, 64, 0),                    #2 conv\n",
    "            Conv_Unit(64, 64, 1)                     #3 conv\n",
    "\n",
    "        )\n",
    "\n",
    "        self.encoder_2 = nn.Sequential(\n",
    "\n",
    "            Pooling_Unit(64),                        #1 max pool\n",
    "            Conv_Unit(64, 128, 0),                   #4 conv\n",
    "            Conv_Unit(128, 128, 0),                  #5 conv\n",
    "            Conv_Unit(128, 128, 1)                   #6 conv\n",
    "\n",
    "        )\n",
    "\n",
    "        self.encoder_3 = nn.Sequential(\n",
    "\n",
    "            Pooling_Unit(128),                       #2 max pool \n",
    "            Conv_Unit(128, 256, 0),                  #7 conv\n",
    "            Conv_Unit(256, 256, 0),                  #8 conv\n",
    "            Conv_Unit(256, 256, 1)                   #9 conv\n",
    "        \n",
    "        )\n",
    "\n",
    "        self.encoder_4 = nn.Sequential(\n",
    "\n",
    "            Pooling_Unit(256),                       #3 max pool\n",
    "            Conv_Unit(256, 512, 0),                 #10 conv\n",
    "            Conv_Unit(512, 512, 0),                 #11 conv\n",
    "            Conv_Unit(512, 512, 1),                 #12 conv\n",
    "        \n",
    "        )\n",
    "\n",
    "        self.bottleneck_decoder_1 = nn.Sequential(\n",
    "\n",
    "            Pooling_Unit(512),                       #4 max pool\n",
    "            Conv_Unit(512, 1024, 0),                #13 conv\n",
    "            Conv_Unit(1024, 1024, 0),               #14 conv\n",
    "            Conv_Unit(1024, 1024, 0),               #15 conv\n",
    "            Trans_Conv_Unit(1024, 512)               #1 transposed conv\n",
    "                \n",
    "        )\n",
    "\n",
    "        self.decoder_2 = nn.Sequential(\n",
    "\n",
    "            Conv_Unit(1024, 512, 0),                #16 conv\n",
    "            Conv_Unit(512, 512, 0),                 #17 conv\n",
    "            Conv_Unit(512, 512, 0),                 #18 conv\n",
    "            Trans_Conv_Unit(512, 256)                #2 transposed conv\n",
    "\n",
    "        )\n",
    "\n",
    "        self.decoder_3 = nn.Sequential(\n",
    "\n",
    "            Conv_Unit(512, 256, 0),                 #19 conv\n",
    "            Conv_Unit(256, 256, 0),                 #20 conv\n",
    "            Conv_Unit(256, 256, 0),                 #21 conv\n",
    "            Trans_Conv_Unit(256, 128)                #3 transposed conv\n",
    "\n",
    "        )\n",
    "\n",
    "        self.decoder_4 = nn.Sequential(\n",
    "\n",
    "            Conv_Unit(256, 128, 0),                 #22 conv\n",
    "            Conv_Unit(128, 128, 0),                 #23 conv\n",
    "            Conv_Unit(128, 128, 0),                 #24 conv\n",
    "            Trans_Conv_Unit(128, 64)                 #4 transposed conv\n",
    "\n",
    "        )\n",
    "\n",
    "        self.decoder_5 = nn.Sequential(\n",
    "\n",
    "            Conv_Unit(128, 64, 0),                  #25 conv\n",
    "            Conv_Unit(64, 64, 0),                   #26 conv\n",
    "            Conv_Unit(64, 64, 0),                   #27 conv\n",
    "            Conv_Unit(64, 3, 0)                        #28 conv [out]\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, L):\n",
    "\n",
    "        first_encoded = self.encoder_1(L)\n",
    "        second_encoded = self.encoder_2(first_encoded)\n",
    "        third_encoded = self.encoder_3(second_encoded)\n",
    "        fourth_encoded = self.encoder_4(third_encoded)\n",
    "\n",
    "        bottleneck_first_decoded = self.bottleneck_decoder_1(fourth_encoded)                                \n",
    "        bottleneck_first_decoded = torch.cat((bottleneck_first_decoded, fourth_encoded), dim = 1)           #skip connection 1\n",
    "\n",
    "        second_decoded = self.decoder_2(bottleneck_first_decoded)\n",
    "        second_decoded = torch.cat((second_decoded, third_encoded), dim = 1)                                #skip connection 2\n",
    "\n",
    "        third_decoded = self.decoder_3(second_decoded)\n",
    "        third_decoded = torch.cat((third_decoded, second_encoded), dim = 1)                                 #skip connection 3\n",
    "        \n",
    "        fourth_decoded = self.decoder_4(third_decoded)                                                      \n",
    "        fourth_decoded = torch.cat((fourth_decoded, first_encoded), dim = 1)                                #skip connection 4\n",
    "\n",
    "        out = self.decoder_5(fourth_decoded)\n",
    "\n",
    "        return out\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAR_UNet() #the dimensional flow WITHIN the u-net lines up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001) #our intended optimizing function, to be paired with the MAE loss function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
